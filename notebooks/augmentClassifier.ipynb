{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83b50bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'SubsetRandomSampler'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mrandom\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m defaultdict, Counter\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSubsetRandomSampler\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Interpolation fallback (handles different torchvision/PIL versions)\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'SubsetRandomSampler'"
     ]
    }
   ],
   "source": [
    "#CELL 1\n",
    "import os, math, random, json\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler, SubsetRandomSampler\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np, random\n",
    "from collections import defaultdict, Counter\n",
    "# Interpolation fallback (handles different torchvision/PIL versions)\n",
    "try:\n",
    "    from torchvision.transforms import InterpolationMode\n",
    "    BICUBIC = InterpolationMode.BICUBIC\n",
    "except Exception:\n",
    "    from PIL import Image as _PIL_Image\n",
    "    BICUBIC = _PIL_Image.BICUBIC\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954a581f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DATASET_ROOT: ../dataset\n",
      "CWD: c:\\Users\\Max\\Desktop\\ComputerVision\\INF3001_Project\\notebooks\n",
      "Looking for: C:\\Users\\Max\\Desktop\\ComputerVision\\INF3001_Project\\dataset\\train\n",
      "Exists? True\n"
     ]
    }
   ],
   "source": [
    "# ==== EDIT THIS if your folder isn't \"dataset\" under the notebook's cwd ====\n",
    "# e.g. r\"C:\\Users\\Max\\Desktop\\ComputerVision\\INF3001_Project\\dataset\"\n",
    "#CELL 2\n",
    "\n",
    "DATASET_ROOT   = \"../dataset\"\n",
    "\n",
    "# ==== no need to touch below (defaults) ====\n",
    "TRAIN_DIR      = f\"{DATASET_ROOT}/train\"   # we’ll split this virtually\n",
    "CHECKPOINT_PATH = \"augment_classifier_best.pth\"\n",
    "CLASS_MAP_JSON  = \"class_mapping.json\"\n",
    "\n",
    "IMAGE_SIZE   = 224\n",
    "BATCH_SIZE   = 32\n",
    "EPOCHS       = 8\n",
    "LEARNING_RATE= 3e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "NUM_WORKERS  = 2\n",
    "USE_AMP      = True\n",
    "VAL_RATIO    = 0.2     # 20% validation from train\n",
    "SEED         = 42\n",
    "print(\"Using DATASET_ROOT:\", DATASET_ROOT)\n",
    "print(\"CWD:\", Path.cwd())\n",
    "print(\"Looking for:\", Path(TRAIN_DIR).resolve())\n",
    "print(\"Exists?\", Path(TRAIN_DIR).is_dir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d9a377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforms ready ✅\n"
     ]
    }
   ],
   "source": [
    "#CELL 3\n",
    "# Data augmentation and normalization for training\n",
    "try:\n",
    "    from torchvision.transforms import InterpolationMode\n",
    "    _BICUBIC = InterpolationMode.BICUBIC\n",
    "except Exception:\n",
    "    _BICUBIC = _PIL_Image.BICUBIC\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    import torch\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(SEED)\n",
    "\n",
    "IM_MEAN = [0.485, 0.456, 0.406]\n",
    "IM_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.7, 1.0), interpolation=_BICUBIC),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=12),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IM_MEAN, IM_STD),\n",
    "    transforms.RandomErasing(p=0.25, scale=(0.02, 0.15), ratio=(0.3, 3.3)),\n",
    "])\n",
    "\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize(int(IMAGE_SIZE*1.15), interpolation=_BICUBIC),\n",
    "    transforms.CenterCrop(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IM_MEAN, IM_STD),\n",
    "])\n",
    "\n",
    "print(\"Transforms ready ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688790fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: {0: 'helmet', 1: 'no_helmet'}\n",
      "Train counts: {'helmet': 648, 'no_helmet': 648}\n",
      "Val counts: {'helmet': 162, 'no_helmet': 162}\n",
      "Loaders ready ✅\n"
     ]
    }
   ],
   "source": [
    "#CELL 4\n",
    "\n",
    "root = Path(TRAIN_DIR)\n",
    "assert root.is_dir(), f\"Training directory not found: {root}\\n(Does {DATASET_ROOT}/train exist?)\"\n",
    "\n",
    "# Base dataset (to read file list + labels; no transforms here)\n",
    "base_ds = datasets.ImageFolder(str(root))\n",
    "labels = [lbl for _, lbl in base_ds.samples]\n",
    "classes = base_ds.classes\n",
    "num_classes = len(classes)\n",
    "\n",
    "# Build stratified indices\n",
    "by_class = defaultdict(list)\n",
    "for idx, lbl in enumerate(labels):\n",
    "    by_class[lbl].append(idx)\n",
    "\n",
    "rng = random.Random(SEED)\n",
    "train_idx, val_idx = [], []\n",
    "for lbl, idxs in by_class.items():\n",
    "    rng.shuffle(idxs)\n",
    "    k = max(1, int(len(idxs) * VAL_RATIO))\n",
    "    val_idx += idxs[:k]\n",
    "    train_idx += idxs[k:]\n",
    "\n",
    "# Two datasets pointing to the SAME files but different transforms\n",
    "train_ds = datasets.ImageFolder(str(root), transform=train_tfms)\n",
    "val_ds   = datasets.ImageFolder(str(root), transform=val_tfms)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE,\n",
    "    sampler=SubsetRandomSampler(train_idx),\n",
    "    num_workers=NUM_WORKERS, pin_memory=(device.type==\"cuda\")\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=BATCH_SIZE,\n",
    "    sampler=SubsetRandomSampler(val_idx),\n",
    "    num_workers=NUM_WORKERS, pin_memory=(device.type==\"cuda\")\n",
    ")\n",
    "\n",
    "# Save class mapping for inference later\n",
    "idx_to_class = {i: c for i, c in enumerate(classes)}\n",
    "import json\n",
    "with open(CLASS_MAP_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(idx_to_class, f, indent=2)\n",
    "\n",
    "# Summary\n",
    "cnt_train = Counter(classes[labels[i]] for i in train_idx)\n",
    "cnt_val   = Counter(classes[labels[i]] for i in val_idx)\n",
    "print(\"Classes:\", idx_to_class)\n",
    "print(\"Train counts:\", dict(cnt_train))\n",
    "print(\"Val counts:\", dict(cnt_val))\n",
    "print(\"Loaders ready ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaea452e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Max\\AppData\\Local\\Temp\\ipykernel_15456\\1047153875.py:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type==\"cuda\" and USE_AMP))\n",
      "C:\\Users\\Max\\AppData\\Local\\Temp\\ipykernel_15456\\1047153875.py:20: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\" and USE_AMP)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/8 | train 0.5839/0.7184 | val 0.7702/0.7562\n",
      "  ✓ Saved best (0.7562) → augment_classifier_best.pth\n",
      "Epoch 02/8 | train 0.4019/0.8472 | val 0.4518/0.8426\n",
      "  ✓ Saved best (0.8426) → augment_classifier_best.pth\n",
      "Epoch 03/8 | train 0.3267/0.8981 | val 0.5131/0.8395\n",
      "Epoch 04/8 | train 0.2776/0.9244 | val 0.5323/0.8426\n",
      "Epoch 05/8 | train 0.2437/0.9468 | val 0.6246/0.8241\n",
      "Epoch 06/8 | train 0.2418/0.9421 | val 0.5079/0.8272\n",
      "Epoch 07/8 | train 0.2204/0.9591 | val 0.5235/0.8426\n",
      "Epoch 08/8 | train 0.2043/0.9653 | val 0.5205/0.8364\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Model Training (Modified to Store Losses)\n",
    "try:\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "except Exception:\n",
    "    model = models.resnet18(pretrained=True)  # older torchvision fallback\n",
    "model.fc = nn.Linear(model.fc.in_features, len(classes))\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(device.type==\"cuda\" and USE_AMP))\n",
    "\n",
    "def acc(logits, y): return (logits.argmax(1)==y).float().mean().item()\n",
    "\n",
    "def train_one_epoch():\n",
    "    model.train(); tl=ta=n=0\n",
    "    for x,y in train_loader:\n",
    "        x=x.to(device,non_blocking=True); y=y.to(device,non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\" and USE_AMP)):\n",
    "            logits=model(x); loss=criterion(logits,y)\n",
    "        scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()\n",
    "        bs=x.size(0); tl+=loss.item()*bs; ta+=acc(logits,y)*bs; n+=bs\n",
    "    return tl/n, ta/n\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate():\n",
    "    model.eval(); vl=va=n=0\n",
    "    for x,y in val_loader:\n",
    "        x=x.to(device,non_blocking=True); y=y.to(device,non_blocking=True)\n",
    "        logits=model(x); loss=criterion(logits,y)\n",
    "        bs=x.size(0); vl+=loss.item()*bs; va+=acc(logits,y)*bs; n+=bs\n",
    "    return vl/n, va/n\n",
    "\n",
    "# Initialize lists to store losses\n",
    "train_losses, val_losses = [], []\n",
    "best = 0.0\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    tl, ta = train_one_epoch()\n",
    "    vl, va = evaluate()\n",
    "    train_losses.append(tl)  # Store training loss\n",
    "    val_losses.append(vl)    # Store validation loss\n",
    "    print(f\"Epoch {epoch:02d}/{EPOCHS} | train {tl:.4f}/{ta:.4f} | val {vl:.4f}/{va:.4f}\")\n",
    "    if va > best:\n",
    "        best = va\n",
    "        torch.save(model.state_dict(), CHECKPOINT_PATH)\n",
    "        print(f\"  ✓ Saved best ({best:.4f}) → {CHECKPOINT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1558b47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Cell 6: Test Loss Calculation and Loss Visualization (Matplotlib Only)\n",
    "\n",
    "# Define test directory and check if it exists\n",
    "TEST_DIR = f\"{DATASET_ROOT}/test\"  # Assuming test folder exists\n",
    "test_exists = Path(TEST_DIR).is_dir()\n",
    "\n",
    "# Function to compute test loss\n",
    "@torch.no_grad()\n",
    "def compute_test_loss(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss, n = 0, 0\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        bs = x.size(0)\n",
    "        test_loss += loss.item() * bs\n",
    "        n += bs\n",
    "    return test_loss / n if n > 0 else 0\n",
    "\n",
    "# Compute test loss if test directory exists\n",
    "test_loss = None\n",
    "if test_exists:\n",
    "    # Create test dataset and loader with same transforms as validation\n",
    "    test_ds = datasets.ImageFolder(str(TEST_DIR), transform=val_tfms)\n",
    "    test_loader = DataLoader(\n",
    "        test_ds, batch_size=BATCH_SIZE,\n",
    "        shuffle=False, num_workers=NUM_WORKERS, pin_memory=(device.type == \"cuda\")\n",
    "    )\n",
    "    # Compute test loss\n",
    "    test_loss = compute_test_loss(model, test_loader, criterion, device)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "else:\n",
    "    print(\"Test directory not found. Skipping test loss calculation.\")\n",
    "\n",
    "# Plot losses using matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, EPOCHS + 1), train_losses, label=\"Training Loss\", color=\"#1f77b4\")\n",
    "plt.plot(range(1, EPOCHS + 1), val_losses, label=\"Validation Loss\", color=\"#ff7f0e\")\n",
    "if test_loss is not None:\n",
    "    plt.axhline(y=test_loss, color=\"#2ca02c\", linestyle=\"--\", label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training, Validation, and Test Loss per Epoch\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7e07976",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict(image_path, checkpoint_path=CHECKPOINT_PATH):\n",
    "    with open(CLASS_MAP_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "        idx_to_class_local = json.load(f)\n",
    "    num_classes = len(idx_to_class_local)\n",
    "\n",
    "    try:\n",
    "        m = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    except Exception:\n",
    "        m = models.resnet18(pretrained=True)\n",
    "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
    "    m.load_state_dict(torch.load(checkpoint_path, map_location=\"cpu\"))\n",
    "    m.eval()\n",
    "\n",
    "    # use the same val transforms\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    x = val_tfms(img).unsqueeze(0)\n",
    "    logits = m(x)\n",
    "    probs = F.softmax(logits, dim=1).squeeze(0).tolist()\n",
    "    pred_idx = int(np.argmax(probs))\n",
    "    return idx_to_class_local[str(pred_idx)], probs\n",
    "\n",
    "# Example:\n",
    "# pred, probs = predict(r\"path\\to\\some\\image.jpg\"); pred, probs[:2]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
